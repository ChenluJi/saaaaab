{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a76835c23d72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ACAD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m62\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "stock = ['ACAD']\n",
    "pages = 62\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for item in stock:\n",
    "    for page in range(pages):\n",
    "        web = 'http://finance.yahoo.com/q/hp?s=' + item + '&a=4&b=10&c=2000&d=5&e=13&f=2016&g=d&z=66&y=' + str(page * 66)\n",
    "        html = urllib.urlopen(web).read()\n",
    "        soup = BeautifulSoup(html)\n",
    "        table = soup.find(\"table\", attrs={'class','yfnc_datamodoutline1'})\n",
    "        if table == None:\n",
    "            continue\n",
    "        rows = [] # store all of the records in this list\n",
    "        \n",
    "        for row in table.findAll('tr'):\n",
    "            cells = []\n",
    "            for cell in row.findAll('td'):\n",
    "                value = cell.get_text().strip()\n",
    "                cells.append(value)\n",
    "            rows.append(cells)\n",
    "\n",
    "        df1 = pd.DataFrame(rows)\n",
    "        df1 = df1[df1.index[[0,1,2,3,4,5,6]]]\n",
    "        df1 = df1.drop(df1.index[[0,1,-1]])\n",
    "        df1.columns = ['Date','Open','High','Low','Close','Volume','Adj Close*']\n",
    "        df = pd.concat([df,df1])\n",
    "        \n",
    "    df.to_csv('/Users/JJason/Documents/Study/summer project/saaaaab/data/' + item +'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Draw the names of stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/Users/pengfeiwang/Desktop/stocks.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-dd532ddadb48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/pengfeiwang/Desktop/stocks.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Company'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/JJason/miniconda3/envs/sabgaze/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal, **kwds)\u001b[0m\n\u001b[1;32m   1341\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1343\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JJason/miniconda3/envs/sabgaze/lib/python2.7/site-packages/pandas/core/format.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1523\u001b[0m             f = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m   1524\u001b[0m                             \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m                             compression=self.compression)\n\u001b[0m\u001b[1;32m   1526\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JJason/miniconda3/envs/sabgaze/lib/python2.7/site-packages/pandas/io/common.pyc\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path, mode, encoding, compression)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/Users/pengfeiwang/Desktop/stocks.csv'"
     ]
    }
   ],
   "source": [
    "pages = 4\n",
    "for page in range(pages):\n",
    "    web = 'http://finance.yahoo.com/q/cp?s=%5ENBI&c=' + str(page)\n",
    "    html = urllib.urlopen(web).read()\n",
    "    soup = BeautifulSoup(html)\n",
    "    table = soup.find(\"table\", attrs={'class','yfnc_tableout1'})\n",
    "    rows = [] # store all of the records in this list\n",
    "    df = pd.DataFrame()\n",
    "        \n",
    "    for row in table.findAll('tr'):\n",
    "        cells = []\n",
    "        for cell in row.findAll('td'):\n",
    "            value = cell.get_text().strip()\n",
    "            cells.append(value)\n",
    "        rows.append(cells)\n",
    "            \n",
    "    stocks = pd.DataFrame(rows)\n",
    "    stocks = stocks[stocks.index[[0]]]\n",
    "    stocks = stocks.drop(stocks.index[[0,1]])\n",
    "    df = pd.concat([df,stocks])  \n",
    "        \n",
    "df.to_csv('/Users/pengfeiwang/Desktop/stocks.csv', index = False, header = ['Company'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stock_name = pd.read_csv('/Users/JJason/Desktop/stocks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_list = list(stock_name.unstack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALKS',\n",
       " 'ALNY',\n",
       " 'ALXN',\n",
       " 'AMAG',\n",
       " 'AMGN',\n",
       " 'AMPH',\n",
       " 'AMRI',\n",
       " 'AMRN',\n",
       " 'ANAC',\n",
       " 'ANIP',\n",
       " 'ANTH',\n",
       " 'AQXP',\n",
       " 'ARDX',\n",
       " 'ARIA',\n",
       " 'ARNA',\n",
       " 'ARRY',\n",
       " 'ARWR',\n",
       " 'ATRA',\n",
       " 'BCRX',\n",
       " 'BIIB',\n",
       " 'BLCM',\n",
       " 'BLUE',\n",
       " 'BMRN',\n",
       " 'BPMC',\n",
       " 'CARA',\n",
       " 'CASC',\n",
       " 'CBPO',\n",
       " 'CCXI',\n",
       " 'CELG',\n",
       " 'CEMP',\n",
       " 'CERS',\n",
       " 'CGEN',\n",
       " 'CHMA',\n",
       " 'CHRS',\n",
       " 'CLDX',\n",
       " 'CLVS',\n",
       " 'CMRX',\n",
       " 'CNCE',\n",
       " 'COLL',\n",
       " 'CRIS',\n",
       " 'CXRX',\n",
       " 'DBVT',\n",
       " 'DEPO',\n",
       " 'DERM',\n",
       " 'DNAI',\n",
       " 'DRNA',\n",
       " 'DRRX',\n",
       " 'ECYT',\n",
       " 'EGLT',\n",
       " 'EGRX',\n",
       " 'ENDP',\n",
       " 'ENTA',\n",
       " 'EPZM',\n",
       " 'ESPR',\n",
       " 'EXEL',\n",
       " 'FGEN',\n",
       " 'FLKS',\n",
       " 'FLML',\n",
       " 'FLXN',\n",
       " 'FMI',\n",
       " 'FOLD',\n",
       " 'FOMX',\n",
       " 'FPRX',\n",
       " 'GERN',\n",
       " 'GHDX',\n",
       " 'GILD',\n",
       " 'GRFS',\n",
       " 'GWPH',\n",
       " 'HALO',\n",
       " 'HZNP',\n",
       " 'ICPT',\n",
       " 'ILMN',\n",
       " 'IMDZ',\n",
       " 'IMGN',\n",
       " 'IMMU',\n",
       " 'INCR',\n",
       " 'INCY',\n",
       " 'INFI',\n",
       " 'INO',\n",
       " 'INSM',\n",
       " 'INSY',\n",
       " 'INVA',\n",
       " 'IONS',\n",
       " 'IPXL',\n",
       " 'IRWD',\n",
       " 'ITEK',\n",
       " 'JAZZ',\n",
       " 'JUNO',\n",
       " 'KITE',\n",
       " 'KMPH',\n",
       " 'KPTI',\n",
       " 'LBIO',\n",
       " 'LGND',\n",
       " 'LIFE',\n",
       " 'LMNX',\n",
       " 'LXRX',\n",
       " 'MACK',\n",
       " 'MCRB',\n",
       " 'MDCO',\n",
       " 'MDVN',\n",
       " 'MGNX',\n",
       " 'MNKD',\n",
       " 'MNTA',\n",
       " 'MYGN',\n",
       " 'MYL',\n",
       " 'NBIX',\n",
       " 'NDRM',\n",
       " 'NEOS',\n",
       " 'NK',\n",
       " 'NKTR',\n",
       " 'NLNK',\n",
       " 'NSTG',\n",
       " 'NVAX',\n",
       " 'OCUL',\n",
       " 'OMED',\n",
       " 'OMER',\n",
       " 'ONCE',\n",
       " 'OPHT',\n",
       " 'OREX',\n",
       " 'OSIR',\n",
       " 'OTIC',\n",
       " 'OVAS',\n",
       " 'PACB',\n",
       " 'PCRX',\n",
       " 'PDLI',\n",
       " 'PETX',\n",
       " 'PGNX',\n",
       " 'PRAH',\n",
       " 'PRTA',\n",
       " 'PTCT',\n",
       " 'PTLA',\n",
       " 'QGEN',\n",
       " 'QURE',\n",
       " 'RARE',\n",
       " 'RDUS',\n",
       " 'REGN',\n",
       " 'RGEN',\n",
       " 'RGLS',\n",
       " 'RIGL',\n",
       " 'RLYP',\n",
       " 'RPTP',\n",
       " 'RTRX',\n",
       " 'RVNC',\n",
       " 'SAGE',\n",
       " 'SCLN',\n",
       " 'SCMP',\n",
       " 'SGEN',\n",
       " 'SGMO',\n",
       " 'SGNT',\n",
       " 'SGYP',\n",
       " 'SHPG',\n",
       " 'SPPI',\n",
       " 'SQNM',\n",
       " 'SRPT',\n",
       " 'SUPN',\n",
       " 'TBPH',\n",
       " 'TECH',\n",
       " 'TKAI',\n",
       " 'TLGT',\n",
       " 'TRVN',\n",
       " 'TSRO',\n",
       " 'TTPH',\n",
       " 'UTHR',\n",
       " 'VNDA',\n",
       " 'VRTX',\n",
       " 'VSAR',\n",
       " 'VTAE',\n",
       " 'VTL',\n",
       " 'XBIT',\n",
       " 'XLRN',\n",
       " 'XNCR',\n",
       " 'XNPT',\n",
       " 'ZFGN',\n",
       " 'ZGNX']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list[7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACAD has been download\n",
      "ACHN has been download\n",
      "ACOR has been download\n",
      "ADHD has been download\n",
      "ADMS has been download\n",
      "ADRO has been download\n",
      "ADVM has been download\n",
      "AEGR has been download\n",
      "AERI has been download\n",
      "AFMD has been download\n",
      "AGIO has been download\n",
      "AGTC has been download\n",
      "AKBA has been download\n",
      "AKRX has been download\n",
      "ALDR has been download\n",
      "ALKS has been download\n",
      "ALNY has been download\n",
      "ALXN has been download\n",
      "AMAG has been download\n",
      "AMGN has been download\n",
      "AMPH has been download\n",
      "AMRI has been download\n",
      "AMRN has been download\n",
      "ANAC has been download\n",
      "ANIP has been download\n",
      "ANTH has been download\n",
      "AQXP has been download\n",
      "ARDX has been download\n",
      "ARIA has been download\n",
      "ARNA has been download\n",
      "ARRY has been download\n",
      "ARWR has been download\n",
      "ATRA has been download\n",
      "BCRX has been download\n",
      "BIIB has been download\n",
      "BLCM has been download\n",
      "BLUE has been download\n",
      "BMRN has been download\n",
      "BPMC has been download\n",
      "CARA has been download\n",
      "CASC has been download\n",
      "CBPO has been download\n",
      "CCXI has been download\n",
      "CELG has been download\n",
      "CEMP has been download\n",
      "CERS has been download\n",
      "CGEN has been download\n",
      "CHMA has been download\n",
      "CHRS has been download\n",
      "CLDX has been download\n",
      "CLVS has been download\n",
      "CMRX has been download\n",
      "CNCE has been download\n",
      "COLL has been download\n",
      "CRIS has been download\n",
      "CXRX has been download\n",
      "DBVT has been download\n",
      "DEPO has been download\n",
      "DERM has been download\n",
      "DNAI has been download\n",
      "DRNA has been download\n",
      "DRRX has been download\n",
      "ECYT has been download\n",
      "EGLT has been download\n",
      "EGRX has been download\n",
      "ENDP has been download\n",
      "ENTA has been download\n",
      "EPZM has been download\n",
      "ESPR has been download\n",
      "EXEL has been download\n",
      "FGEN has been download\n",
      "FLKS has been download\n",
      "FLML has been download\n",
      "FLXN has been download\n",
      "FMI has been download\n",
      "FOLD has been download\n",
      "FOMX has been download\n",
      "FPRX has been download\n",
      "GERN has been download\n",
      "GHDX has been download\n",
      "GILD has been download\n",
      "GRFS has been download\n",
      "GWPH has been download\n",
      "HALO has been download\n",
      "HZNP has been download\n",
      "ICPT has been download\n",
      "ILMN has been download\n",
      "IMDZ has been download\n",
      "IMGN has been download\n",
      "IMMU has been download\n",
      "INCR has been download\n",
      "INCY has been download\n",
      "INFI has been download\n",
      "INO has been download\n",
      "INSM has been download\n",
      "INSY has been download\n",
      "INVA has been download\n",
      "IONS has been download\n",
      "IPXL has been download\n",
      "IRWD has been download\n",
      "ITEK has been download\n",
      "JAZZ has been download\n",
      "JUNO has been download\n",
      "KITE has been download\n",
      "KMPH has been download\n",
      "KPTI has been download\n",
      "LBIO has been download\n",
      "LGND has been download\n",
      "LIFE has been download\n",
      "LMNX has been download\n",
      "LXRX has been download\n",
      "MACK has been download\n",
      "MCRB has been download\n",
      "MDCO has been download\n",
      "MDVN has been download\n",
      "MGNX has been download\n",
      "MNKD has been download\n",
      "MNTA has been download\n",
      "MYGN has been download\n",
      "MYL has been download\n",
      "NBIX has been download\n",
      "NDRM has been download\n",
      "NEOS has been download\n",
      "NK has been download\n",
      "NKTR has been download\n",
      "NLNK has been download\n",
      "NSTG has been download\n",
      "NVAX has been download\n",
      "OCUL has been download\n",
      "OMED has been download\n",
      "OMER has been download\n",
      "ONCE has been download\n",
      "OPHT has been download\n",
      "OREX has been download\n",
      "OSIR has been download\n",
      "OTIC has been download\n",
      "OVAS has been download\n",
      "PACB has been download\n",
      "PCRX has been download\n",
      "PDLI has been download\n",
      "PETX has been download\n",
      "PGNX has been download\n",
      "PRAH has been download\n",
      "PRTA has been download\n",
      "PTCT has been download\n",
      "PTLA has been download\n",
      "QGEN has been download\n",
      "QURE has been download\n",
      "RARE has been download\n",
      "RDUS has been download\n",
      "REGN has been download\n",
      "RGEN has been download\n",
      "RGLS has been download\n",
      "RIGL has been download\n",
      "RLYP has been download\n",
      "RPTP has been download\n",
      "RTRX has been download\n",
      "RVNC has been download\n",
      "SAGE has been download\n",
      "SCLN has been download\n",
      "SCMP has been download\n",
      "SGEN has been download\n",
      "SGMO has been download\n",
      "SGNT has been download\n",
      "SGYP has been download\n",
      "SHPG has been download\n",
      "SPPI has been download\n",
      "SQNM has been download\n",
      "SRPT has been download\n",
      "SUPN has been download\n",
      "TBPH has been download\n",
      "TECH has been download\n",
      "TKAI has been download\n",
      "TLGT has been download\n",
      "TRVN has been download\n",
      "TSRO has been download\n",
      "TTPH has been download\n",
      "UTHR has been download\n",
      "VNDA has been download\n",
      "VRTX has been download\n",
      "VSAR has been download\n",
      "VTAE has been download\n",
      "VTL has been download\n",
      "XBIT has been download\n",
      "XLRN has been download\n",
      "XNCR has been download\n",
      "XNPT has been download\n",
      "ZFGN has been download\n",
      "ZGNX has been download\n"
     ]
    }
   ],
   "source": [
    "stock = name_list\n",
    "pages = 10\n",
    "\n",
    "for item in stock:\n",
    "    df = pd.DataFrame()\n",
    "    for page in range(pages):\n",
    "        web = 'http://finance.yahoo.com/q/hp?s=' + item + '&a=4&b=10&c=2000&d=5&e=13&f=2016&g=d&z=66&y=' + str(page * 66)\n",
    "        html = urllib.urlopen(web).read()\n",
    "        soup = BeautifulSoup(html)\n",
    "        table = soup.find(\"table\", attrs={'class','yfnc_datamodoutline1'})\n",
    "        if table == None:\n",
    "            continue\n",
    "        rows = [] # store all of the records in this list\n",
    "        \n",
    "        for row in table.findAll('tr'):\n",
    "            cells = []\n",
    "            for cell in row.findAll('td'):\n",
    "                value = cell.get_text().strip()\n",
    "                cells.append(value)\n",
    "            rows.append(cells)\n",
    "\n",
    "        df1 = pd.DataFrame(rows)\n",
    "        df1 = df1.loc[:,[0,1,2,3,4,5,6]]\n",
    "        #df1 = df1[df1.index[[0,1,2,3,4,5,6]]]\n",
    "        df1 = df1.drop(df1.index[[0,1,-1]])\n",
    "        df1.columns = ['Date','Open','High','Low','Close','Volume','Adj Close*']\n",
    "        df = pd.concat([df,df1])\n",
    "        \n",
    "    df.to_csv('/Users/JJason/Documents/Study/summer project/saaaaab/data/' + item +'.csv',index=False)\n",
    "    print item + ' has been download'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
